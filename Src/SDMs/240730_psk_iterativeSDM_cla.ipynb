{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef05f187",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import rasterio\n",
    "import shapely\n",
    "import geopandas as gpd\n",
    "import shutil\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split \n",
    "from pyimpute import load_training_vector\n",
    "from pyimpute import load_targets\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.inspection import partial_dependence\n",
    "import shap\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from pyimpute import impute\n",
    "from sklearn import model_selection as mod_sel\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import confusion_matrix as evaluate_conf\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9a057dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/pranavkulkarni/SDM/Climate_Models_Arenaviruses'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"/Users/pranavkulkarni/SDM/Climate_Models_Arenaviruses\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71886f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_xs_list = []\n",
    "train_y_list = []\n",
    "test_xs_list = []\n",
    "test_y_list = []\n",
    "raster_info = []\n",
    "target_xs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce5618c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'transform': Affine(0.041666666666666664, 0.0, -76.08333333333333,\n",
       "        0.0, -0.041666666666666664, -17.625),\n",
       " 'shape': (999, 597),\n",
       " 'crs': CRS.from_epsg(4326)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_xs_list = np.load(\"/Users/pranavkulkarni/SDM/Climate_Models_Arenaviruses/Data/Inter/train_test_npz/cla_train_xs.npz\")['arr_0']\n",
    "train_y_list = np.load(\"/Users/pranavkulkarni/SDM/Climate_Models_Arenaviruses/Data/Inter/train_test_npz/cla_train_y.npz\")['arr_0']\n",
    "test_xs_list = np.load(\"/Users/pranavkulkarni/SDM/Climate_Models_Arenaviruses/Data/Inter/train_test_npz/cla_test_xs.npz\")['arr_0']\n",
    "test_y_list = np.load(\"/Users/pranavkulkarni/SDM/Climate_Models_Arenaviruses/Data/Inter/train_test_npz/cla_test_y.npz\")['arr_0']\n",
    "raster_info = np.load(\"/Users/pranavkulkarni/SDM/Climate_Models_Arenaviruses/Data/Inter/train_test_npz/cla_raster_info.npz\", allow_pickle = True)['arr_0']\n",
    "target_xs = np.load(\"/Users/pranavkulkarni/SDM/Climate_Models_Arenaviruses/Data/Inter/train_test_npz/cla_target_xs.npz\")['arr_0']\n",
    "raster_info = raster_info[0]\n",
    "raster_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c37cfd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 205, 24)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_xs_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83619fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = [\"Annual Mean Temperature\",\n",
    "                \"Mean Diurnal Range\",\n",
    "                \"Isothermality\",\n",
    "                \"Temperature Seasonality\",\n",
    "                \"Max Temperature of Warmest Month\",\n",
    "                \"Min Temperature of Coldest Month\",\n",
    "                \"Temperature Annual Range\",\n",
    "                \"Mean Temperature of Wettest Quarter\",\n",
    "                \"Mean Temperature of Driest Quarter\",\n",
    "                 \"Mean Temperature of Warmest Quarter\",\n",
    "                 \"Mean Temperature of Coldest Quarter\",\n",
    "                \"Annual Precipitation\",\n",
    "                \"Precipitation of Wettest Month\",\n",
    "                \"Precipitation of Driest Month\",\n",
    "                \"Precipitation Seasonality\",\n",
    "                \"Precipitation of Wettest Quarter\",\n",
    "                \"Precipitation of Driest Quarter\",\n",
    "                 \"Precipitation of Warmest Quarter\",\n",
    "                \"Precipitation of Coldest Quarter\",\n",
    "                 \"LUcrop\",\n",
    "                \"LUothr\",\n",
    "                \"LUpast\",\n",
    "                \"LUsecd\",\n",
    "                \"LUurbn\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc0693ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssp2 = sorted(glob.glob(\"./Data/Input/Processed/Projected/junin/SSP2/*.tif\"))\n",
    "ssp5 = sorted(glob.glob(\"./Data/Input/Processed/Projected/junin/SSP5/*.tif\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d812b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(596403, 24) (596403, 24)\n"
     ]
    }
   ],
   "source": [
    "target_ssp2, ssp2_info = load_targets(ssp2)\n",
    "target_ssp2[np.isnan(target_ssp2)] = 0\n",
    "\n",
    "target_ssp5, ssp5_info = load_targets(ssp5)\n",
    "target_ssp5[np.isnan(target_ssp5)] = 0\n",
    "print(target_ssp2.shape, target_ssp5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3f80e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_MAP = {\n",
    "    \"rf\": (RandomForestClassifier()),\n",
    "    \"et\": (ExtraTreesClassifier()),\n",
    "    \"xgb\": (XGBClassifier()),\n",
    "    \"lgbm\": (LGBMClassifier(verbose = -1))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5f6ec85",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('./Data/Output/iterations/C_laucha'):\n",
    "    print('name folders exists')\n",
    "else: \n",
    "    os.mkdir('./Data/Output/iterations/C_laucha')\n",
    "if os.path.exists('./Data/Output/iterations/C_laucha/current'):\n",
    "    print('name folders exists')\n",
    "else: \n",
    "    os.mkdir('./Data/Output/iterations/C_laucha/current')\n",
    "if os.path.exists('./Data/Output/iterations/C_laucha/ssp2'):\n",
    "    print('name folders exists')\n",
    "else: \n",
    "    os.mkdir('./Data/Output/iterations/C_laucha/ssp2')\n",
    "if os.path.exists('./Data/Output/iterations/C_laucha/ssp5'):\n",
    "    print('name folders exists')\n",
    "else: \n",
    "    os.mkdir('./Data/Output/iterations/C_laucha/ssp5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab85b9d",
   "metadata": {},
   "source": [
    "# Single run for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df646b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.28773165e+00, 5.62638903e+00, 4.44578552e+01, ...,\n",
       "        4.24947450e-03, 5.31766018e-05, 0.00000000e+00],\n",
       "       [1.69134998e+01, 1.30323334e+01, 4.83682175e+01, ...,\n",
       "        4.33063924e-01, 1.54282702e-02, 1.67206710e-03],\n",
       "       [2.63215008e+01, 1.04483337e+01, 6.22517395e+01, ...,\n",
       "        4.30562824e-01, 1.01373315e-01, 6.05659967e-04],\n",
       "       ...,\n",
       "       [1.81795006e+01, 1.20843334e+01, 5.15191574e+01, ...,\n",
       "        1.57422990e-01, 4.52285349e-01, 8.17791279e-03],\n",
       "       [2.48840008e+01, 1.39146671e+01, 5.89904480e+01, ...,\n",
       "        5.56552768e-01, 1.15860072e-04, 1.91561398e-04],\n",
       "       [1.66841660e+01, 1.01276665e+01, 4.34216537e+01, ...,\n",
       "        2.34949812e-01, 2.77831946e-02, 1.73596278e-01]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_xs = train_xs_list[1]\n",
    "train_y = train_y_list[1].copy()\n",
    "\n",
    "test_xs = test_xs_list[1].copy()\n",
    "test_y = test_y_list[1].copy()\n",
    "test_xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05982245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rfCV Accuracy: 77.56 (+/- 5.69)\n",
      "rfCV AUC_ROC: 88.33 (+/- 3.94)\n",
      "rfCV precision: 79.99 (+/- 9.11)\n",
      "rfCV recall: 82.48 (+/- 19.87)\n",
      "[[28  7]\n",
      " [ 7 27]]\n",
      "etCV Accuracy: 78.05 (+/- 6.90)\n",
      "etCV AUC_ROC: 89.52 (+/- 7.02)\n",
      "etCV precision: 77.97 (+/- 13.00)\n",
      "etCV recall: 86.38 (+/- 15.45)\n",
      "[[24 11]\n",
      " [ 7 27]]\n",
      "xgbCV Accuracy: 75.12 (+/- 5.69)\n",
      "xgbCV AUC_ROC: 86.90 (+/- 3.77)\n",
      "xgbCV precision: 74.52 (+/- 7.92)\n",
      "xgbCV recall: 77.71 (+/- 18.45)\n",
      "[[28  7]\n",
      " [ 8 26]]\n",
      "lgbmCV Accuracy: 77.56 (+/- 6.47)\n",
      "lgbmCV AUC_ROC: 87.43 (+/- 6.61)\n",
      "lgbmCV precision: 75.05 (+/- 7.40)\n",
      "lgbmCV recall: 83.52 (+/- 9.51)\n",
      "[[30  5]\n",
      " [ 6 28]]\n"
     ]
    }
   ],
   "source": [
    "for name, (model) in CLASS_MAP.items():\n",
    "    rfe = RFE(estimator = model, n_features_to_select = 10)\n",
    "    pipeline = Pipeline(steps=[('Feature Selection', rfe), ('Model', model)])\n",
    "    k = 5\n",
    "    kf = mod_sel.KFold(n_splits = k)\n",
    "    accu_score = mod_sel.cross_val_score(pipeline, train_xs, train_y, cv = kf, scoring = \"accuracy\")\n",
    "    print(name + \"CV Accuracy: %0.2f (+/- %0.2f)\"\n",
    "                    % (accu_score.mean() * 100, accu_score.std() * 200))\n",
    "    accuracy_scores = mod_sel.cross_val_score(pipeline, train_xs, train_y, cv=kf, scoring='roc_auc')\n",
    "    print(name + \"CV AUC_ROC: %0.2f (+/- %0.2f)\"\n",
    "                    % (accuracy_scores.mean() * 100, accuracy_scores.std() * 200))\n",
    "    accuracy_scores_p = mod_sel.cross_val_score(pipeline, train_xs, train_y, cv=kf, scoring='precision')\n",
    "    print(name + \"CV precision: %0.2f (+/- %0.2f)\"\n",
    "                    % (accuracy_scores_p.mean() * 100, accuracy_scores_p.std() * 200))\n",
    "    accuracy_scores_r = mod_sel.cross_val_score(pipeline, train_xs, train_y, cv=kf, scoring='recall')\n",
    "    print(name + \"CV recall: %0.2f (+/- %0.2f)\"\n",
    "                    % (accuracy_scores_r.mean() * 100, accuracy_scores_r.std() * 200))\n",
    "    pipeline.fit(train_xs, train_y)\n",
    "    y_pred = pipeline.predict(test_xs)\n",
    "    eval1 = evaluate_conf(test_y, y_pred)\n",
    "    print(eval1)\n",
    "    selector = rfe.fit(train_xs, train_y)   \n",
    "    \n",
    "    dir_curr = './Data/Output/iterations/C_laucha/current/' + name + '-images_'\n",
    "    if os.path.exists(dir_curr):\n",
    "        print('name folders exists')\n",
    "    else: \n",
    "        os.mkdir(dir_curr)\n",
    "        \n",
    "    impute(target_xs, selector, raster_info, outdir = dir_curr, class_prob = True, certainty = True)\n",
    "        \n",
    "    dir_ssp2 = './Data/Output/iterations/C_laucha/ssp2/' + name + '-images_'\n",
    "    if os.path.exists(dir_ssp2):\n",
    "        print('name folders exists')\n",
    "    else: \n",
    "        os.mkdir(dir_ssp2)\n",
    "    impute(target_ssp2, selector, ssp2_info, outdir = dir_ssp2, class_prob = True, certainty = True)\n",
    "        \n",
    "    dir_ssp5 = './Data/Output/iterations/C_laucha/ssp5/' + name + '-images_'\n",
    "    if os.path.exists(dir_ssp5):\n",
    "        print('name folders exists')\n",
    "    else: \n",
    "        os.mkdir(dir_ssp5)\n",
    "    impute(target_ssp5, selector, ssp5_info, outdir = dir_ssp5, class_prob = True, certainty = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9933803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Mean Diurnal Range', 'Max Temperature of Warmest Month',\n",
       "       'Temperature Annual Range', 'Mean Temperature of Wettest Quarter',\n",
       "       'Mean Temperature of Driest Quarter', 'Precipitation Seasonality',\n",
       "       'Precipitation of Warmest Quarter', 'LUcrop', 'LUpast', 'LUurbn'],\n",
       "      dtype='<U35')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sed = selector.fit(train_xs, train_y).support_\n",
    "np.array(feature_names)[sed]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1809795e",
   "metadata": {},
   "source": [
    "# Iterations\n",
    "\n",
    "## under construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1ec442e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 5 runs\n",
      "Completed 10 runs\n",
      "Completed 15 runs\n",
      "Completed 20 runs\n",
      "Completed 25 runs\n",
      "Completed 30 runs\n",
      "Completed 35 runs\n",
      "Completed 40 runs\n",
      "Completed 45 runs\n",
      "Completed 50 runs\n",
      "CPU times: user 1h 14min 58s, sys: 22min 55s, total: 1h 37min 54s\n",
      "Wall time: 38min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import warnings  \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "num_runs = 50\n",
    "\n",
    "dfs_model = []\n",
    "\n",
    "list_pd_results = []\n",
    "list_shap_results = []\n",
    "\n",
    "features_rf = []\n",
    "features_et = []\n",
    "features_xgb = []\n",
    "features_lgbm = []\n",
    "\n",
    "for run in range(num_runs):\n",
    "    model_results = []\n",
    "    pd_results = []\n",
    "    shap_results = []\n",
    "    \n",
    "    for name, model in CLASS_MAP.items():\n",
    "        rfe = RFE(estimator = model, n_features_to_select = 10)\n",
    "        k = 5  \n",
    "        kf = mod_sel.KFold(n_splits=k)\n",
    "        selector = rfe.fit(train_xs_list[run], train_y_list[run])\n",
    "        sed = selector.support_\n",
    "        accu_score = mod_sel.cross_val_score(selector, \n",
    "                                             train_xs_list[run], \n",
    "                                             train_y_list[run], \n",
    "                                             cv = kf, \n",
    "                                             scoring = \"accuracy\")\n",
    "        acc_score_mean = accu_score.mean() * 100\n",
    "        acc_score_std = accu_score.std() * 200\n",
    "        \n",
    "        accuracy_scores = mod_sel.cross_val_score(selector, \n",
    "                                                          train_xs_list[run], \n",
    "                                                          train_y_list[run], \n",
    "                                                          cv=kf, scoring='roc_auc')\n",
    "        roc_auc_mean = accuracy_scores.mean() * 100\n",
    "        roc_auc_std = accuracy_scores.std() * 200\n",
    "\n",
    "        accuracy_scores_p = mod_sel.cross_val_score(selector, \n",
    "                                                          train_xs_list[run], \n",
    "                                                          train_y_list[run], \n",
    "                                                          cv=kf, scoring='precision')\n",
    "        precision_mean = accuracy_scores_p.mean() * 100\n",
    "        precision_std = accuracy_scores_p.std() * 200\n",
    "\n",
    "        accuracy_scores_r = mod_sel.cross_val_score(selector, \n",
    "                                                          train_xs_list[run], \n",
    "                                                          train_y_list[run], \n",
    "                                                          cv=kf, scoring='recall')\n",
    "        recall_mean = accuracy_scores_r.mean() * 100\n",
    "        recall_std = accuracy_scores_r.std() * 200\n",
    "        \n",
    "        y_pred = selector.predict(test_xs_list[run])\n",
    "        eval1 = evaluate_conf(test_y_list[run], y_pred)\n",
    "        \n",
    "        model_results.append({\n",
    "            'Model': name,\n",
    "            'Run': run + 1,\n",
    "            'Acc_mean': acc_score_mean,\n",
    "            'ACC_std': acc_score_std,\n",
    "            'ROC_AUC_mean': roc_auc_mean,\n",
    "            'ROC_AUC_std': roc_auc_std,\n",
    "            'Precision_mean': precision_mean,\n",
    "            'Precision_std': precision_std,\n",
    "            'Recall_mean': recall_mean,\n",
    "            'Recall_std':recall_std,\n",
    "            'tp': eval1[0][0],\n",
    "            'fp': eval1[0][1],\n",
    "            'fn': eval1[1][0],\n",
    "            'tn': eval1[1][1]\n",
    "        })\n",
    "        \n",
    "        selector.fit(train_xs_list[run], train_y_list[run])\n",
    "#         dir_curr = './Data/Output/iterations/C_callosus/current/' + name + '-images_' + str(run)\n",
    "#         if os.path.exists(dir_curr):\n",
    "#             print('name folders exists')\n",
    "#         else: \n",
    "#             os.mkdir(dir_curr)\n",
    "#         impute(target_xs, model, raster_info, outdir = dir_curr, class_prob = True, certainty = True)\n",
    "        \n",
    "#         dir_ssp2 = './Data/Output/iterations/C_callosus/ssp2/' + name + '-images_' + str(run)\n",
    "#         if os.path.exists(dir_ssp2):\n",
    "#             print('name folders exists')\n",
    "#         else: \n",
    "#             os.mkdir(dir_ssp2)\n",
    "#         impute(target_ssp2, model, ssp2_info, outdir = dir_ssp2, class_prob = True, certainty = True)\n",
    "        \n",
    "#         dir_ssp5 = './Data/Output/iterations/C_callosus/ssp5/' + name + '-images_' + str(run)\n",
    "#         if os.path.exists(dir_ssp5):\n",
    "#             print('name folders exists')\n",
    "#         else: \n",
    "#             os.mkdir(dir_ssp5)\n",
    "#         impute(target_ssp5, model, ssp5_info, outdir = dir_ssp5, class_prob = True, certainty = True)\n",
    "        for i in np.arange(len(np.array(feature_names)[sed])).tolist():\n",
    "        \n",
    "            a_df = pd.DataFrame({np.array(feature_names)[sed][i] + \"_grid\": \n",
    "                  partial_dependence(selector, train_xs, [i])[\"grid_values\"][0], \n",
    "                  np.array(feature_names)[sed][i] + \"_avg\": \n",
    "                  partial_dependence(selector, train_xs, [i])[\"average\"][0]})\n",
    "            pd_results.append(a_df)\n",
    "            \n",
    "#         explainer = shap.TreeExplainer(model)  \n",
    "#         shap_values = explainer.shap_values(train_xs_list[run])\n",
    "        \n",
    "#         explainer = shap.TreeExplainer(model)  \n",
    "#         new_train = train_xs_list[run][:,sed]\n",
    "#         shap_values = explainer.shap_values(new_train)\n",
    "#         shap_results.append(shap_values)\n",
    "        if name == 'rf':\n",
    "            importances = model.feature_importances_\n",
    "            forest_importances = pd.Series(importances, index=np.array(feature_names)[sed])\n",
    "            features_rf.append(forest_importances)\n",
    "        if name == 'et':\n",
    "            importances = model.feature_importances_\n",
    "            et_importances = pd.Series(importances, index=np.array(feature_names)[sed])\n",
    "            features_et.append(et_importances)        \n",
    "        if name == 'xgb':\n",
    "            importances = model.feature_importances_\n",
    "            xgb_importances = pd.Series(importances, index=np.array(feature_names)[sed])       \n",
    "            features_xgb.append(xgb_importances)     \n",
    "        if name == 'lgbm':\n",
    "            importances = model.feature_importances_\n",
    "            gain_importance = (model.feature_importances_ / sum(model.feature_importances_)) \n",
    "            lgbm_importances = pd.Series(gain_importance, index=np.array(feature_names)[sed]) \n",
    "            features_lgbm.append(lgbm_importances)          \n",
    "    list_pd_results.append(pd_results)\n",
    "#     list_shap_results.append(shap_results)\n",
    "    \n",
    "    model_results_run_df = pd.DataFrame(model_results)\n",
    "    dfs_model.append(model_results_run_df)\n",
    "    if (run + 1) % 5 == 0:\n",
    "        print(f\"Completed {run + 1} runs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e453237",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Data/Output/iterations/C_laucha/pd_results.pkl', 'wb') as f:\n",
    "    pickle.dump(list_pd_results, f)\n",
    "    \n",
    "# with open('./Data/Output/iterations/C_laucha/shap_results.pkl', 'wb') as f:\n",
    "#     pickle.dump(list_shap_results, f)\n",
    "    \n",
    "model_results_df = pd.concat(dfs_model, ignore_index=True)\n",
    "features_rf = pd.concat(features_rf)\n",
    "features_et = pd.concat(features_et)\n",
    "features_xgb = pd.concat(features_xgb)\n",
    "features_lgbm = pd.concat(features_lgbm)\n",
    "\n",
    "model_results_df.to_csv('./Data/Output/iterations/C_laucha/model_results.csv', index=True)\n",
    "features_rf.to_csv('./Data/Output/iterations/C_laucha/rf_results.csv', index=True)\n",
    "features_et.to_csv('./Data/Output/iterations/C_laucha/et_results.csv', index=True)\n",
    "features_xgb.to_csv('./Data/Output/iterations/C_laucha/xgb_results.csv', index=True)\n",
    "features_lgbm.to_csv('./Data/Output/iterations/C_laucha/lgbm_results.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6f5859",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef8dead",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f0d4b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa64609",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
