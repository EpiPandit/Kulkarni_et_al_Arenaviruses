{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef05f187",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import rasterio\n",
    "import shapely\n",
    "import geopandas as gpd\n",
    "import shutil\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split \n",
    "from pyimpute import load_training_vector\n",
    "from pyimpute import load_targets\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.inspection import partial_dependence\n",
    "import shap\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from pyimpute import impute\n",
    "from sklearn import model_selection as mod_sel\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import confusion_matrix as evaluate_conf\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9a057dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/pranavkulkarni/SDM/Climate_Models_Arenaviruses'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"/Users/pranavkulkarni/SDM/Climate_Models_Arenaviruses\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71886f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_xs_list = []\n",
    "train_y_list = []\n",
    "test_xs_list = []\n",
    "test_y_list = []\n",
    "raster_info = []\n",
    "target_xs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce5618c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'transform': Affine(0.041666666666666664, 0.0, -84.75,\n",
       "        0.0, -0.041666666666666664, 14.375),\n",
       " 'shape': (450, 900),\n",
       " 'crs': CRS.from_epsg(4326)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_xs_list = np.load(\"/Users/pranavkulkarni/SDM/Climate_Models_Arenaviruses/Data/Inter/train_test_npz/zyg_train_xs.npz\")['arr_0']\n",
    "train_y_list = np.load(\"/Users/pranavkulkarni/SDM/Climate_Models_Arenaviruses/Data/Inter/train_test_npz/zyg_train_y.npz\")['arr_0']\n",
    "test_xs_list = np.load(\"/Users/pranavkulkarni/SDM/Climate_Models_Arenaviruses/Data/Inter/train_test_npz/zyg_test_xs.npz\")['arr_0']\n",
    "test_y_list = np.load(\"/Users/pranavkulkarni/SDM/Climate_Models_Arenaviruses/Data/Inter/train_test_npz/zyg_test_y.npz\")['arr_0']\n",
    "raster_info = np.load(\"/Users/pranavkulkarni/SDM/Climate_Models_Arenaviruses/Data/Inter/train_test_npz/zyg_raster_info.npz\", allow_pickle = True)['arr_0']\n",
    "target_xs = np.load(\"/Users/pranavkulkarni/SDM/Climate_Models_Arenaviruses/Data/Inter/train_test_npz/zyg_target_xs.npz\")['arr_0']\n",
    "raster_info = raster_info[0]\n",
    "raster_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c37cfd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 1032, 26)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_xs_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83619fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = [\"Annual Mean Temperature\",\n",
    "                \"Mean Diurnal Range\",\n",
    "                \"Isothermality\",\n",
    "                \"Temperature Seasonality\",\n",
    "                \"Max Temperature of Warmest Month\",\n",
    "                \"Min Temperature of Coldest Month\",\n",
    "                \"Temperature Annual Range\",\n",
    "                \"Mean Temperature of Wettest Quarter\",\n",
    "                \"Mean Temperature of Driest Quarter\",\n",
    "                 \"Mean Temperature of Warmest Quarter\",\n",
    "                 \"Mean Temperature of Coldest Quarter\",\n",
    "                \"Annual Precipitation\",\n",
    "                \"Precipitation of Wettest Month\",\n",
    "                \"Precipitation of Driest Month\",\n",
    "                \"Precipitation Seasonality\",\n",
    "                \"Precipitation of Wettest Quarter\",\n",
    "                \"Precipitation of Driest Quarter\",\n",
    "                 \"Precipitation of Warmest Quarter\",\n",
    "                \"Precipitation of Coldest Quarter\",\n",
    "                 \"DEM\",\n",
    "                 \"LUcrop\",\n",
    "                \"LUothr\",\n",
    "                \"LUpast\",\n",
    "                \"LUsecd\",\n",
    "                \"LUurbn\",\n",
    "                \"NDVI\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc0693ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssp2 = sorted(glob.glob(\"./Data/Input/Processed/Projected/guan/SSP2/*.tif\"))\n",
    "ssp5 = sorted(glob.glob(\"./Data/Input/Processed/Projected/guan/SSP5/*.tif\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d812b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(405000, 26) (405000, 26)\n"
     ]
    }
   ],
   "source": [
    "target_ssp2, ssp2_info = load_targets(ssp2)\n",
    "target_ssp2[np.isnan(target_ssp2)] = 0\n",
    "\n",
    "target_ssp5, ssp5_info = load_targets(ssp5)\n",
    "target_ssp5[np.isnan(target_ssp5)] = 0\n",
    "print(target_ssp2.shape, target_ssp5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3f80e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_MAP = {\n",
    "    \"rf\": (RandomForestClassifier()),\n",
    "    \"et\": (ExtraTreesClassifier()),\n",
    "    \"xgb\": (XGBClassifier()),\n",
    "    \"lgbm\": (LGBMClassifier(verbose = -1))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5f6ec85",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('./Data/Output/iterations/Z_brevicauda'):\n",
    "    print('name folders exists')\n",
    "else: \n",
    "    os.mkdir('./Data/Output/iterations/Z_brevicauda')\n",
    "if os.path.exists('./Data/Output/iterations/Z_brevicauda/current'):\n",
    "    print('name folders exists')\n",
    "else: \n",
    "    os.mkdir('./Data/Output/iterations/Z_brevicauda/current')\n",
    "if os.path.exists('./Data/Output/iterations/Z_brevicauda/ssp2'):\n",
    "    print('name folders exists')\n",
    "else: \n",
    "    os.mkdir('./Data/Output/iterations/Z_brevicauda/ssp2')\n",
    "if os.path.exists('./Data/Output/iterations/Z_brevicauda/ssp5'):\n",
    "    print('name folders exists')\n",
    "else: \n",
    "    os.mkdir('./Data/Output/iterations/Z_brevicauda/ssp5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab85b9d",
   "metadata": {},
   "source": [
    "# Single run for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df646b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.57064991e+01, 8.00766659e+00, 8.82679214e+01, ...,\n",
       "        5.07845998e-01, 8.20000016e-04, 3.59100014e-01],\n",
       "       [2.82098331e+01, 1.03103333e+01, 8.39877396e+01, ...,\n",
       "        7.07271993e-01, 0.00000000e+00, 2.62899995e-01],\n",
       "       [2.59289989e+01, 8.86000061e+00, 8.12545929e+01, ...,\n",
       "        6.76089972e-02, 0.00000000e+00, 7.05900013e-01],\n",
       "       ...,\n",
       "       [2.74340000e+01, 8.79599953e+00, 7.87889633e+01, ...,\n",
       "        5.25195003e-01, 0.00000000e+00, 4.58200008e-01],\n",
       "       [1.49095001e+01, 9.74366665e+00, 8.19622040e+01, ...,\n",
       "        1.41452000e-01, 2.28760000e-02, 4.39820353e-01],\n",
       "       [1.97443333e+01, 9.29399967e+00, 8.70550766e+01, ...,\n",
       "        5.21454990e-01, 4.91000013e-04, 5.97000010e-02]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_xs = train_xs_list[1]\n",
    "train_y = train_y_list[1].copy()\n",
    "\n",
    "test_xs = test_xs_list[1].copy()\n",
    "test_y = test_y_list[1].copy()\n",
    "test_xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05982245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rfCV Accuracy: 87.11 (+/- 1.95)\n",
      "rfCV AUC_ROC: 94.97 (+/- 0.85)\n",
      "rfCV precision: 88.45 (+/- 5.35)\n",
      "rfCV recall: 87.59 (+/- 3.19)\n",
      "[[150  22]\n",
      " [ 37 135]]\n",
      "etCV Accuracy: 87.69 (+/- 2.82)\n",
      "etCV AUC_ROC: 95.55 (+/- 0.88)\n",
      "etCV precision: 86.51 (+/- 5.21)\n",
      "etCV recall: 89.91 (+/- 4.55)\n",
      "[[151  21]\n",
      " [ 30 142]]\n",
      "xgbCV Accuracy: 86.53 (+/- 3.74)\n",
      "xgbCV AUC_ROC: 94.49 (+/- 0.80)\n",
      "xgbCV precision: 85.32 (+/- 6.44)\n",
      "xgbCV recall: 88.37 (+/- 2.41)\n",
      "[[150  22]\n",
      " [ 34 138]]\n",
      "lgbmCV Accuracy: 86.43 (+/- 2.92)\n",
      "lgbmCV AUC_ROC: 95.24 (+/- 1.57)\n",
      "lgbmCV precision: 86.27 (+/- 3.22)\n",
      "lgbmCV recall: 86.61 (+/- 3.52)\n",
      "[[151  21]\n",
      " [ 33 139]]\n"
     ]
    }
   ],
   "source": [
    "for name, (model) in CLASS_MAP.items():\n",
    "    rfe = RFE(estimator = model, n_features_to_select = 10)\n",
    "    pipeline = Pipeline(steps=[('Feature Selection', rfe), ('Model', model)])\n",
    "    k = 5\n",
    "    kf = mod_sel.KFold(n_splits = k)\n",
    "    accu_score = mod_sel.cross_val_score(pipeline, train_xs, train_y, cv = kf, scoring = \"accuracy\")\n",
    "    print(name + \"CV Accuracy: %0.2f (+/- %0.2f)\"\n",
    "                    % (accu_score.mean() * 100, accu_score.std() * 200))\n",
    "    accuracy_scores = mod_sel.cross_val_score(pipeline, train_xs, train_y, cv=kf, scoring='roc_auc')\n",
    "    print(name + \"CV AUC_ROC: %0.2f (+/- %0.2f)\"\n",
    "                    % (accuracy_scores.mean() * 100, accuracy_scores.std() * 200))\n",
    "    accuracy_scores_p = mod_sel.cross_val_score(pipeline, train_xs, train_y, cv=kf, scoring='precision')\n",
    "    print(name + \"CV precision: %0.2f (+/- %0.2f)\"\n",
    "                    % (accuracy_scores_p.mean() * 100, accuracy_scores_p.std() * 200))\n",
    "    accuracy_scores_r = mod_sel.cross_val_score(pipeline, train_xs, train_y, cv=kf, scoring='recall')\n",
    "    print(name + \"CV recall: %0.2f (+/- %0.2f)\"\n",
    "                    % (accuracy_scores_r.mean() * 100, accuracy_scores_r.std() * 200))\n",
    "    pipeline.fit(train_xs, train_y)\n",
    "    y_pred = pipeline.predict(test_xs)\n",
    "    eval1 = evaluate_conf(test_y, y_pred)\n",
    "    print(eval1)\n",
    "    selector = rfe.fit(train_xs, train_y)   \n",
    "    \n",
    "    dir_curr = './Data/Output/iterations/Z_brevicauda/current/' + name + '-images_'\n",
    "    if os.path.exists(dir_curr):\n",
    "        print('name folders exists')\n",
    "    else: \n",
    "        os.mkdir(dir_curr)\n",
    "        \n",
    "    impute(target_xs, selector, raster_info, outdir = dir_curr, class_prob = True, certainty = True)\n",
    "        \n",
    "    dir_ssp2 = './Data/Output/iterations/Z_brevicauda/ssp2/' + name + '-images_'\n",
    "    if os.path.exists(dir_ssp2):\n",
    "        print('name folders exists')\n",
    "    else: \n",
    "        os.mkdir(dir_ssp2)\n",
    "    impute(target_ssp2, selector, ssp2_info, outdir = dir_ssp2, class_prob = True, certainty = True)\n",
    "        \n",
    "    dir_ssp5 = './Data/Output/iterations/Z_brevicauda/ssp5/' + name + '-images_'\n",
    "    if os.path.exists(dir_ssp5):\n",
    "        print('name folders exists')\n",
    "    else: \n",
    "        os.mkdir(dir_ssp5)\n",
    "    impute(target_ssp5, selector, ssp5_info, outdir = dir_ssp5, class_prob = True, certainty = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9933803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Isothermality', 'Temperature Seasonality',\n",
       "       'Precipitation of Wettest Month', 'Precipitation Seasonality',\n",
       "       'Precipitation of Warmest Quarter',\n",
       "       'Precipitation of Coldest Quarter', 'DEM', 'LUcrop', 'LUpast',\n",
       "       'NDVI'], dtype='<U35')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sed = selector.fit(train_xs, train_y).support_\n",
    "np.array(feature_names)[sed]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1809795e",
   "metadata": {},
   "source": [
    "# Iterations\n",
    "\n",
    "## under construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1ec442e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 5 runs\n",
      "Completed 10 runs\n",
      "Completed 15 runs\n",
      "Completed 20 runs\n",
      "Completed 25 runs\n",
      "Completed 30 runs\n",
      "Completed 35 runs\n",
      "Completed 40 runs\n",
      "Completed 45 runs\n",
      "Completed 50 runs\n",
      "CPU times: user 4h 8min 19s, sys: 1h 28min 35s, total: 5h 36min 54s\n",
      "Wall time: 2h 26min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import warnings  \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "num_runs = 50\n",
    "\n",
    "dfs_model = []\n",
    "\n",
    "list_pd_results = []\n",
    "list_shap_results = []\n",
    "\n",
    "features_rf = []\n",
    "features_et = []\n",
    "features_xgb = []\n",
    "features_lgbm = []\n",
    "\n",
    "for run in range(num_runs):\n",
    "    model_results = []\n",
    "    pd_results = []\n",
    "    shap_results = []\n",
    "    \n",
    "    for name, model in CLASS_MAP.items():\n",
    "        rfe = RFE(estimator = model, n_features_to_select = 10)\n",
    "        k = 5  \n",
    "        kf = mod_sel.KFold(n_splits=k)\n",
    "        selector = rfe.fit(train_xs_list[run], train_y_list[run])\n",
    "        sed = selector.support_\n",
    "        accu_score = mod_sel.cross_val_score(selector, \n",
    "                                             train_xs_list[run], \n",
    "                                             train_y_list[run], \n",
    "                                             cv = kf, \n",
    "                                             scoring = \"accuracy\")\n",
    "        acc_score_mean = accu_score.mean() * 100\n",
    "        acc_score_std = accu_score.std() * 200\n",
    "        \n",
    "        accuracy_scores = mod_sel.cross_val_score(selector, \n",
    "                                                          train_xs_list[run], \n",
    "                                                          train_y_list[run], \n",
    "                                                          cv=kf, scoring='roc_auc')\n",
    "        roc_auc_mean = accuracy_scores.mean() * 100\n",
    "        roc_auc_std = accuracy_scores.std() * 200\n",
    "\n",
    "        accuracy_scores_p = mod_sel.cross_val_score(selector, \n",
    "                                                          train_xs_list[run], \n",
    "                                                          train_y_list[run], \n",
    "                                                          cv=kf, scoring='precision')\n",
    "        precision_mean = accuracy_scores_p.mean() * 100\n",
    "        precision_std = accuracy_scores_p.std() * 200\n",
    "\n",
    "        accuracy_scores_r = mod_sel.cross_val_score(selector, \n",
    "                                                          train_xs_list[run], \n",
    "                                                          train_y_list[run], \n",
    "                                                          cv=kf, scoring='recall')\n",
    "        recall_mean = accuracy_scores_r.mean() * 100\n",
    "        recall_std = accuracy_scores_r.std() * 200\n",
    "        \n",
    "        y_pred = selector.predict(test_xs_list[run])\n",
    "        eval1 = evaluate_conf(test_y_list[run], y_pred)\n",
    "        \n",
    "        model_results.append({\n",
    "            'Model': name,\n",
    "            'Run': run + 1,\n",
    "            'Acc_mean': acc_score_mean,\n",
    "            'ACC_std': acc_score_std,\n",
    "            'ROC_AUC_mean': roc_auc_mean,\n",
    "            'ROC_AUC_std': roc_auc_std,\n",
    "            'Precision_mean': precision_mean,\n",
    "            'Precision_std': precision_std,\n",
    "            'Recall_mean': recall_mean,\n",
    "            'Recall_std':recall_std,\n",
    "            'tp': eval1[0][0],\n",
    "            'fp': eval1[0][1],\n",
    "            'fn': eval1[1][0],\n",
    "            'tn': eval1[1][1]\n",
    "        })\n",
    "        \n",
    "        selector.fit(train_xs_list[run], train_y_list[run])\n",
    "#         dir_curr = './Data/Output/iterations/C_callosus/current/' + name + '-images_' + str(run)\n",
    "#         if os.path.exists(dir_curr):\n",
    "#             print('name folders exists')\n",
    "#         else: \n",
    "#             os.mkdir(dir_curr)\n",
    "#         impute(target_xs, model, raster_info, outdir = dir_curr, CLAss_prob = True, certainty = True)\n",
    "        \n",
    "#         dir_ssp2 = './Data/Output/iterations/C_callosus/ssp2/' + name + '-images_' + str(run)\n",
    "#         if os.path.exists(dir_ssp2):\n",
    "#             print('name folders exists')\n",
    "#         else: \n",
    "#             os.mkdir(dir_ssp2)\n",
    "#         impute(target_ssp2, model, ssp2_info, outdir = dir_ssp2, CLAss_prob = True, certainty = True)\n",
    "        \n",
    "#         dir_ssp5 = './Data/Output/iterations/C_callosus/ssp5/' + name + '-images_' + str(run)\n",
    "#         if os.path.exists(dir_ssp5):\n",
    "#             print('name folders exists')\n",
    "#         else: \n",
    "#             os.mkdir(dir_ssp5)\n",
    "#         impute(target_ssp5, model, ssp5_info, outdir = dir_ssp5, CLAss_prob = True, certainty = True)\n",
    "        for i in np.arange(len(np.array(feature_names)[sed])).tolist():\n",
    "        \n",
    "            a_df = pd.DataFrame({np.array(feature_names)[sed][i] + \"_grid\": \n",
    "                  partial_dependence(selector, train_xs, [i])[\"grid_values\"][0], \n",
    "                  np.array(feature_names)[sed][i] + \"_avg\": \n",
    "                  partial_dependence(selector, train_xs, [i])[\"average\"][0]})\n",
    "            pd_results.append(a_df)\n",
    "            \n",
    "#         explainer = shap.TreeExplainer(model)  \n",
    "#         shap_values = explainer.shap_values(train_xs_list[run])\n",
    "        \n",
    "#         explainer = shap.TreeExplainer(model)  \n",
    "#         new_train = train_xs_list[run][:,sed]\n",
    "#         shap_values = explainer.shap_values(new_train)\n",
    "#         shap_results.append(shap_values)\n",
    "        if name == 'rf':\n",
    "            importances = model.feature_importances_\n",
    "            forest_importances = pd.Series(importances, index=np.array(feature_names)[sed])\n",
    "            features_rf.append(forest_importances)\n",
    "        if name == 'et':\n",
    "            importances = model.feature_importances_\n",
    "            et_importances = pd.Series(importances, index=np.array(feature_names)[sed])\n",
    "            features_et.append(et_importances)        \n",
    "        if name == 'xgb':\n",
    "            importances = model.feature_importances_\n",
    "            xgb_importances = pd.Series(importances, index=np.array(feature_names)[sed])       \n",
    "            features_xgb.append(xgb_importances)     \n",
    "        if name == 'lgbm':\n",
    "            importances = model.feature_importances_\n",
    "            gain_importance = (model.feature_importances_ / sum(model.feature_importances_)) \n",
    "            lgbm_importances = pd.Series(gain_importance, index=np.array(feature_names)[sed]) \n",
    "            features_lgbm.append(lgbm_importances)          \n",
    "    list_pd_results.append(pd_results)\n",
    "#     list_shap_results.append(shap_results)\n",
    "    \n",
    "    model_results_run_df = pd.DataFrame(model_results)\n",
    "    dfs_model.append(model_results_run_df)\n",
    "    if (run + 1) % 5 == 0:\n",
    "        print(f\"Completed {run + 1} runs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e453237",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Data/Output/iterations/Z_brevicauda/pd_results.pkl', 'wb') as f:\n",
    "    pickle.dump(list_pd_results, f)\n",
    "    \n",
    "# with open('./Data/Output/iterations/Z_brevicauda/shap_results.pkl', 'wb') as f:\n",
    "#     pickle.dump(list_shap_results, f)\n",
    "    \n",
    "model_results_df = pd.concat(dfs_model, ignore_index=True)\n",
    "features_rf = pd.concat(features_rf)\n",
    "features_et = pd.concat(features_et)\n",
    "features_xgb = pd.concat(features_xgb)\n",
    "features_lgbm = pd.concat(features_lgbm)\n",
    "\n",
    "model_results_df.to_csv('./Data/Output/iterations/Z_brevicauda/model_results.csv', index=True)\n",
    "features_rf.to_csv('./Data/Output/iterations/Z_brevicauda/rf_results.csv', index=True)\n",
    "features_et.to_csv('./Data/Output/iterations/Z_brevicauda/et_results.csv', index=True)\n",
    "features_xgb.to_csv('./Data/Output/iterations/Z_brevicauda/xgb_results.csv', index=True)\n",
    "features_lgbm.to_csv('./Data/Output/iterations/Z_brevicauda/lgbm_results.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6f5859",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef8dead",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f0d4b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa64609",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
